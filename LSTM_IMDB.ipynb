{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_IMDB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snowysunny/Colaboratory/blob/master/LSTM_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Vr2m2FxR1S1x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Simple example using LSTM recurrent neural network to classify IMDB"
      ]
    },
    {
      "metadata": {
        "id": "QvR3HTac1Hmq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# codng: utf-8\n",
        "\n",
        "from __future__ import division, print_function, absolute_import"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Q5wpYSP1vmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "973a7c2f-533c-4f94-e06d-a6e8d44fd0d8"
      },
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.6/dist-packages (0.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.11.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mtDOpoNN1xUF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tflearn\n",
        "from tflearn.data_utils import to_categorical, pad_sequences\n",
        "from tflearn.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jy2utLtV3Dju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s-%(levelname)s-%(message)s\")\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kF_8zAR71-fl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b54ce87f-6196-44fc-b6a8-eb82b2b52c0b"
      },
      "cell_type": "code",
      "source": [
        "# IMDB Dataset loading\n",
        "train, test, _ = imdb.load_data(path='imdb.pkl', n_words=10000, valid_portion=0.1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.iro.umontreal.ca/~lisa/deep/data/imdb.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ntpv7RBn2bC1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainX, trainY = train\n",
        "testX, testY = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X3Hwta-d2hZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0a7da6fb-c7a4-4ad2-90cd-21be302d2239"
      },
      "cell_type": "code",
      "source": [
        "print(type(trainX), len(trainX))\n",
        "print(type(testX), len(testX))\n",
        "print(type(trainX[0]), len(trainX[0]))\n",
        "print(type(testX[0]), len(testX[0]))\n",
        "print(trainX[0])\n",
        "print(testX[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'> 22500\n",
            "<class 'list'> 2500\n",
            "<class 'list'> 11\n",
            "<class 'list'> 22\n",
            "[17, 25, 10, 406, 26, 14, 56, 61, 62, 323, 4]\n",
            "[2, 118, 35, 6186, 5, 2, 242, 10, 397, 4, 14, 20, 6, 456, 7, 2, 1938, 7, 1, 5, 1, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aL-3yhzw2kP1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_X_arr = np.array(testX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vd0tdFFf2ocU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "# Sequence padding\n",
        "\"\"\"\n",
        "pad_sequences是一个把序列转化为固定长度的函数，可以去看源码，有两种展开方式，\n",
        "第一种向前填充，一种是可以向后填充，填充值可以自己指定，可以指定是0，也可以指定是1\n",
        "主要这里的输入是一个int类型的矩阵，\n",
        "\"\"\"\n",
        "trainX = pad_sequences(trainX, maxlen=100, value=0.)    # 处理成100维的向量，不足的使用0补充\n",
        "testX = pad_sequences(testX, maxlen=100, value=0.)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fLYO6sxi2qJV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Converting labels to binary vectors\n",
        "\"\"\"\n",
        "to_categorical 是一个把分类弄成[0,1]\n",
        "[1,0]的形式\n",
        "\"\"\"\n",
        "trainY = to_categorical(trainY, nb_classes=2)\n",
        "testY = to_categorical(testY, nb_classes=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ocIgeg_G62YR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Network building\n",
        "net = tflearn.input_data([None, 100])    # 输入数据\n",
        "\"\"\"\n",
        "input_dim就是看分语料中取了多少个单词，一般取top多少\n",
        "\"\"\"\n",
        "net = tflearn.embedding(net, input_dim=10000, output_dim=128)\n",
        "net = tflearn.lstm(net, 128, dropout=0.8)\n",
        "net = tflearn.fully_connected(net, 2, activation=\"softmax\")\n",
        "net = tflearn.regression(net, optimizer=\"adam\", learning_rate=0.001, loss=\"categorical_crossentropy\")\n",
        "\n",
        "# # Network building\n",
        "# net = tflearn.input_data([None, 100])\n",
        "# net = tflearn.embedding(net, input_dim=10000, output_dim=128)\n",
        "# net = tflearn.lstm(net, 128, dropout=0.8)\n",
        "# net = tflearn.fully_connected(net, 2, activation='softmax')\n",
        "# net = tflearn.regression(net, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tw6Qtha67VKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Trainging\n",
        "#模型初始化\n",
        "model = tflearn.DNN(net, tensorboard_verbose=0,tensorboard_dir=\"/tflearn_logs/\")\n",
        "# model = tflearn.DNN(net, tensorboard_verbose=0)\n",
        "# model.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CO2dCAit9FCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "b71dfbdd-f2a2-4013-9bd4-c57b318dfc47"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "show_metric=True可以看到过程中的准确率\n",
        "\"\"\"\n",
        "model.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True,batch_size=32)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-b83d6af40406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mshow_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue可以看到过程中的准确率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# TODO: check memory impact for large data and multiple optimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         feed_dict = feed_dict_builder(X_inputs, Y_targets, self.inputs,\n\u001b[0;32m--> 184\u001b[0;31m                                       self.targets)\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mfeed_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mval_feed_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tflearn/utils.py\u001b[0m in \u001b[0;36mfeed_dict_builder\u001b[0;34m(X, Y, net_inputs, net_targets)\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# If a dict is provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}