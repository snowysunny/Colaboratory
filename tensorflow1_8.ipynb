{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow1.8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "gTV-R__Uj05B",
        "LhhwC0CjkAiR",
        "usz4tQMkxrLP",
        "ZdQjQJAHMzkm",
        "Zf0htVcCk0K8",
        "EvL_shKAQ_VE",
        "WgfQmarCrGps",
        "xiWUBz3r3nvC"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snowysunny/Colaboratory/blob/master/tensorflow1_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gTV-R__Uj05B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow 安装"
      ]
    },
    {
      "metadata": {
        "id": "UqOxwx08pWsm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 不需要进行安装\n",
        "#! pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eMAOLzPOfAle",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uh5dLWKBf8LL",
        "colab_type": "code",
        "outputId": "4e5406e8-bff9-47f9-cb04-ff62daa7ed59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "A = tf.constant([[1, 2], [3, 4]])\n",
        "B = tf.constant([[5, 6],[7, 8]])\n",
        "C = tf.matmul(A, B)\n",
        "\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[19 22]\n",
            " [43 50]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LhhwC0CjkAiR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow 基础"
      ]
    },
    {
      "metadata": {
        "id": "H_ff9z2ajwuS",
        "colab_type": "code",
        "outputId": "18d91119-6a60-47ed-ba6c-371686e7098a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Tensorflow 1 + 1\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow.python.framework.ops.enable_eager_execution>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "rt5AZEaClYdo",
        "colab_type": "code",
        "outputId": "e3a2f1a2-d085-40c9-80bd-72153311da5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 数值相加\n",
        "a = tf.constant(1)\n",
        "b = tf.constant(1)\n",
        "c = tf.add(a, b)\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F9g8hzweo6JE",
        "colab_type": "code",
        "outputId": "a70c5e69-3722-4a3d-9516-a250f1d1456f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# 矩阵相乘\n",
        "A = tf.constant([[1, 2], [3, 4]])\n",
        "B = tf.constant([[5, 6],[7, 8]])\n",
        "C = tf.matmul(A, B)\n",
        "\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[19 22]\n",
            " [43 50]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NKX8MyAwpsB0",
        "colab_type": "code",
        "outputId": "09b01c5c-9eca-4532-ef4f-57c01feed76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x = tf.get_variable(name='x', shape=[1], initializer=tf.constant_initializer(3.))\n",
        "\n",
        "# 在tf.GradientTape()的上下文内，所有计算步骤都会被记录以用于求导\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.square(x)  # y = x^2\n",
        "  \n",
        "# 计算y关于x的导数\n",
        "y_grad = tape.gradient(y, x)\n",
        "print([y.numpy(), y_grad.numpy()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([9.], dtype=float32), array([6.], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oV_H3k1orKcr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "这里x是一个初始化为3的变量(Variable)，使用tf.get_variable()声明。与普通张量一样，变量同样具有形状(shape)和类型(dtype)属性，不过使用变量需要有一个初始化过程，可以通过在tf.get_variable()中指定initializer参数来指定所使用的的初始化器。\n",
        "\n",
        "变量和普通张量的一个重要区别是其默认能够被Tensorflow的自动求导机制所求导，因此常常被用于定义机器学习模型的参数。tf.GradientTape()是一个自动求导的记录器，在其中变量和计算步骤都会被自动记录。"
      ]
    },
    {
      "metadata": {
        "id": "v8dZitAFqFHT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ti9miiLasan0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**使用tf.GradientTape()计算函数$L(w, b) = ||Xw+b-y||^2$在$w=(1,2)^T, b=1$时对$w, b$的偏导数。 其中$ X=\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\\\ \\end{bmatrix} , y = \\begin{bmatrix} 1 \\\\ 2 \\\\ \\end{bmatrix} $**"
      ]
    },
    {
      "metadata": {
        "id": "NxroLVHXtrWA",
        "colab_type": "code",
        "outputId": "bc56cd4b-b610-4192-c6ac-148e22fa32fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "X = tf.constant([[1., 2.], [3., 4.]])\n",
        "y = tf.constant([[1.], [2.]])\n",
        "w = tf.get_variable('w', shape=[2, 1], initializer=tf.constant_initializer([[1.], [2.]]))\n",
        "b = tf.get_variable('b', shape=[1], initializer=tf.constant_initializer([1.]))\n",
        "with tf.GradientTape() as tape:\n",
        "    L = 0.5 * tf.reduce_sum(tf.square(tf.matmul(X, w) + b - y))     # tf.reduce_sum()操作代表对输入张量的所有元素求和，输出一个形状为空的纯量张量  ， tf.square()操作代表对输入张亮的每一个元素求平方，不改变张量形状\n",
        "\n",
        "w_grad , b_grad = tape.gradient(L, [w, b])\n",
        "print([L.numpy(), w_grad.numpy(), b_grad.numpy()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[62.5, array([[35.],\n",
            "       [50.]], dtype=float32), array([15.], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "usz4tQMkxrLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 基础示例： 线性回归"
      ]
    },
    {
      "metadata": {
        "id": "fSR6YOOvuQUA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_raw = np.array([2013, 2014, 2015, 2016, 2017])\n",
        "y_raw = np.array([12000, 14000, 15000, 16500, 17500])\n",
        "\n",
        "X = (X_raw - X_raw.min()) / (X_raw.max() - X_raw.min())\n",
        "y = (y_raw - y_raw.min()) / (y_raw.max() - y_raw.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QhiS8UrhzyQs",
        "colab_type": "code",
        "outputId": "2a474864-3b8b-4e84-df0d-c8a9c0540305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# 输出参数\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0.   0.25 0.5  0.75 1.  ], shape=(5,), dtype=float64)\n",
            "tf.Tensor([0.         0.36363636 0.54545455 0.81818182 1.        ], shape=(5,), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AXnjnI7W1JR5",
        "colab_type": "code",
        "outputId": "825a61a5-408a-4277-ee25-08d283a2c31f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 权值\n",
        "w = tf.get_variable('w', shape=[], initializer=tf.zeros_initializer(), dtype=tf.float64)\n",
        "b = tf.get_variable('b', shape=[], initializer=tf.zeros_initializer(), dtype=tf.float64)\n",
        "variables = [w, b]\n",
        "print(variables)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'w:0' shape=() dtype=float64, numpy=0.0>, <tf.Variable 'b:0' shape=() dtype=float64, numpy=0.0>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "arBrkplt1vKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epoch = 10000\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51Qt3eph2Jm5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for e in range(num_epoch):\n",
        "    # 使用tf.GradientTape()记录损失函数的梯度信息\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = w * X + b\n",
        "        loss = 0.5 * tf.reduce_sum(tf.square(y_pred - y))\n",
        "    # Tensorflow 自动计算损失函数关于自变量（模型参数）的梯度\n",
        "    grads = tape.gradient(loss, variables)\n",
        "  \n",
        "    # Tensorflow自动根据梯度更新参数\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, variables))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JIZpdyKX3LW5",
        "colab_type": "code",
        "outputId": "dcce8dd0-62e3-4ded-c0df-d4798e8d87c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(w.numpy())\n",
        "print(b.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9763702100237027\n",
            "0.05756498006354141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qhzlol607ckV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">* 使用tape.gradient(ys, xs)自动计算梯度\n",
        ">* 使用optimizer.apply_gradients(grads_and_vars)自动更新模型参数\n",
        ">* 使用tf.train.GradientDescentOptimizer(learning_rate=1e-3)声明一个梯度下降优化器(Optimizer)，学习率为1e-3\n"
      ]
    },
    {
      "metadata": {
        "id": "vcRqUmdQ8oK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZdQjQJAHMzkm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. TensorFlow 模型\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Zf0htVcCk0K8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.1 模型与层"
      ]
    },
    {
      "metadata": {
        "id": "YVPSTDkAMygY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kb0oR6a1NR4O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "y = tf.constant([[10.0], [20.0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5Ya-yXINqMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Linear(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dense = tf.keras.layers.Dense(units=1, kernel_initializer=tf.zeros_initializer(), bias_initializer=tf.zeros_initializer())\n",
        "    \n",
        "    def call(self, input):\n",
        "        output = self.dense(input)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nMNU5CFbOPI-",
        "colab_type": "code",
        "outputId": "0f20e9ed-3f1d-40e1-aa1e-1ecf4656faa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "model = Linear()\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "for i in range(100):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(X)\n",
        "        loss = tf.reduce_sum(tf.square(y_pred-y))\n",
        "    grads = tape.gradient(loss, model.variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "print(model.variables)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'linear/dense_10/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[0.16730969],\n",
            "       [1.1439102 ],\n",
            "       [2.120511  ]], dtype=float32)>, <tf.Variable 'linear/dense_10/bias:0' shape=(1,) dtype=float32, numpy=array([0.97660077], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EvL_shKAQ_VE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.2 基础示例： 多层感知机(MLP)"
      ]
    },
    {
      "metadata": {
        "id": "AkIF_UWsPLw-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 实现一个简单的DataLoader类来读取MNIST数据集数据\n",
        "class DataLoader():\n",
        "    def __init__(self):\n",
        "        mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
        "    \n",
        "        self.train_data = mnist.train.images      # np.array [55000, 748]\n",
        "    \n",
        "        self.train_labels = np.asarray(mnist.train.labels, dtype=np.int32)    # np.array    [55000]  int32\n",
        "\n",
        "        self.eval_data = mnist.test.images        # np.array [10000, 748]\n",
        "    \n",
        "        self.eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)     # np.array      [10000]    int32\n",
        "\n",
        "    # 批量处理数据\n",
        "    def get_batch(self, batch_size):\n",
        "        index = np.random.randint(0, np.shape(self.train_data)[0], batch_size)\n",
        "        return self.train_data[index, :], self.train_labels[index]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z7UUO6S3ahR1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MLP(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # units: 正整数，输出空间维度。\n",
        "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        return x\n",
        "    \n",
        "    def predict(self, inputs):\n",
        "        logits = self(inputs)\n",
        "        return tf.argmax(logits, axis=-1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OhPOX8G9cvIg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_batches=10000\n",
        "batch_size=50    # 批大小\n",
        "learning_rate = 0.001    # 学习率"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gcbj3SGPdjo0",
        "colab_type": "code",
        "outputId": "c46beb8a-d4a5-4c4c-a0b1-a98544b80660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# 实例化模型，数据读取类和优化器\n",
        "data_loader = DataLoader()\n",
        "model = MLP()\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QkrzvZIqeYY4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "然后迭代进行以下步骤：\n",
        ">* 从DataLoader中随机去除一批训练数据\n",
        ">* 将这批数据送入模型，计算出模型的预测值\n",
        ">* 将模型预测值与真实值进行对比，计算损失函数(loss)\n",
        ">* 计算损失函数关于模型变量的导数\n",
        ">* 使用优化器更新模型参数以最小化损失函数\n"
      ]
    },
    {
      "metadata": {
        "id": "-mhcwRQed2PA",
        "colab_type": "code",
        "outputId": "872d683b-d196-41ea-c1e6-44db7609a1d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "for batch_index in range(num_batches):\n",
        "    X, y = data_loader.get_batch(batch_size)\n",
        "  \n",
        "    with tf.GradientTape() as tape:\n",
        "        y_logit_pred = model(tf.convert_to_tensor(X))\n",
        "        loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_logit_pred)\n",
        "        if batch_index %100 == 0:\n",
        "            print(\"batch %d : loss %f\" %(batch_index, loss.numpy()))\n",
        "    grads = tape.gradient(loss, model.variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch 0 : loss 0.342618\n",
            "batch 100 : loss 0.182857\n",
            "batch 200 : loss 0.227622\n",
            "batch 300 : loss 0.257889\n",
            "batch 400 : loss 0.226254\n",
            "batch 500 : loss 0.383519\n",
            "batch 600 : loss 0.218000\n",
            "batch 700 : loss 0.068599\n",
            "batch 800 : loss 0.275217\n",
            "batch 900 : loss 0.148904\n",
            "batch 1000 : loss 0.142543\n",
            "batch 1100 : loss 0.320799\n",
            "batch 1200 : loss 0.141551\n",
            "batch 1300 : loss 0.118681\n",
            "batch 1400 : loss 0.071995\n",
            "batch 1500 : loss 0.220347\n",
            "batch 1600 : loss 0.042813\n",
            "batch 1700 : loss 0.046956\n",
            "batch 1800 : loss 0.133350\n",
            "batch 1900 : loss 0.077915\n",
            "batch 2000 : loss 0.040952\n",
            "batch 2100 : loss 0.124818\n",
            "batch 2200 : loss 0.152551\n",
            "batch 2300 : loss 0.266619\n",
            "batch 2400 : loss 0.031239\n",
            "batch 2500 : loss 0.098745\n",
            "batch 2600 : loss 0.051543\n",
            "batch 2700 : loss 0.334216\n",
            "batch 2800 : loss 0.066380\n",
            "batch 2900 : loss 0.048744\n",
            "batch 3000 : loss 0.044871\n",
            "batch 3100 : loss 0.045026\n",
            "batch 3200 : loss 0.055900\n",
            "batch 3300 : loss 0.077920\n",
            "batch 3400 : loss 0.118902\n",
            "batch 3500 : loss 0.085524\n",
            "batch 3600 : loss 0.015221\n",
            "batch 3700 : loss 0.147607\n",
            "batch 3800 : loss 0.023704\n",
            "batch 3900 : loss 0.047071\n",
            "batch 4000 : loss 0.031727\n",
            "batch 4100 : loss 0.036649\n",
            "batch 4200 : loss 0.021627\n",
            "batch 4300 : loss 0.014867\n",
            "batch 4400 : loss 0.032218\n",
            "batch 4500 : loss 0.051139\n",
            "batch 4600 : loss 0.014146\n",
            "batch 4700 : loss 0.039076\n",
            "batch 4800 : loss 0.010182\n",
            "batch 4900 : loss 0.245159\n",
            "batch 5000 : loss 0.043233\n",
            "batch 5100 : loss 0.015192\n",
            "batch 5200 : loss 0.052239\n",
            "batch 5300 : loss 0.115840\n",
            "batch 5400 : loss 0.071901\n",
            "batch 5500 : loss 0.058122\n",
            "batch 5600 : loss 0.049147\n",
            "batch 5700 : loss 0.027575\n",
            "batch 5800 : loss 0.072413\n",
            "batch 5900 : loss 0.189484\n",
            "batch 6000 : loss 0.124095\n",
            "batch 6100 : loss 0.036037\n",
            "batch 6200 : loss 0.071891\n",
            "batch 6300 : loss 0.074127\n",
            "batch 6400 : loss 0.023636\n",
            "batch 6500 : loss 0.086181\n",
            "batch 6600 : loss 0.039672\n",
            "batch 6700 : loss 0.073611\n",
            "batch 6800 : loss 0.026539\n",
            "batch 6900 : loss 0.030211\n",
            "batch 7000 : loss 0.004212\n",
            "batch 7100 : loss 0.027983\n",
            "batch 7200 : loss 0.023270\n",
            "batch 7300 : loss 0.021379\n",
            "batch 7400 : loss 0.072266\n",
            "batch 7500 : loss 0.074144\n",
            "batch 7600 : loss 0.025644\n",
            "batch 7700 : loss 0.005684\n",
            "batch 7800 : loss 0.018420\n",
            "batch 7900 : loss 0.014381\n",
            "batch 8000 : loss 0.057759\n",
            "batch 8100 : loss 0.002092\n",
            "batch 8200 : loss 0.026740\n",
            "batch 8300 : loss 0.131645\n",
            "batch 8400 : loss 0.012677\n",
            "batch 8500 : loss 0.042133\n",
            "batch 8600 : loss 0.021790\n",
            "batch 8700 : loss 0.078841\n",
            "batch 8800 : loss 0.038765\n",
            "batch 8900 : loss 0.016574\n",
            "batch 9000 : loss 0.025925\n",
            "batch 9100 : loss 0.020709\n",
            "batch 9200 : loss 0.006340\n",
            "batch 9300 : loss 0.019618\n",
            "batch 9400 : loss 0.007819\n",
            "batch 9500 : loss 0.005574\n",
            "batch 9600 : loss 0.009829\n",
            "batch 9700 : loss 0.003676\n",
            "batch 9800 : loss 0.010097\n",
            "batch 9900 : loss 0.041418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h5uc4_U9gC1f",
        "colab_type": "code",
        "outputId": "2708b085-b037-47f4-bdd0-ea15011da4e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "num_eval_samples = np.shape(data_loader.eval_labels)[0]\n",
        "\n",
        "y_pred = model.predict(data_loader.eval_data).numpy()\n",
        "\n",
        "print(\"test accuracy: %f\" % (sum(y_pred == data_loader.eval_labels) / num_eval_samples))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy: 0.973200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WgfQmarCrGps",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.3 卷积神经网络(CNN)"
      ]
    },
    {
      "metadata": {
        "id": "l-gJ684limLM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # filter: 整数，输出空间的维度 （即卷积中滤波器的输出数量）, kernel_size: 卷积核的大小 padding: padding策略，same表示填充输入以使输出具有与原始输入相同的长度 \n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2,2], strides=2)\n",
        "        \n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
        "        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2,2], strides=2)\n",
        "        \n",
        "        self.flatten = tf.keras.layers.Reshape(target_shape=(7*7*64, ))\n",
        "        self.dense1 = tf.keras.layers.Dense(units=1024, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        inputs = tf.reshape(inputs, [-1, 28, 28, 1])\n",
        "        x = self.conv1(inputs)     # [batch_size, 28, 28, 32]\n",
        "        x = self.pool1(x)          # [batch_size, 14, 14, 32]\n",
        "        x = self.conv2(x)          # [batch_size, 14, 14, 64]\n",
        "        x = self.pool2(x)          # [batch_size, 7, 7, 64]\n",
        "        x = self.flatten(x)        # [batch_size, 7 * 7 * 64]\n",
        "        x = self.dense1(x)         # [batch_size, 1024]\n",
        "        x = self.dense2(x)         # [batch_size, 10]\n",
        "        return x\n",
        "    \n",
        "    def predict(self, inputs):\n",
        "        logits = self(inputs)\n",
        "        return tf.argmax(logits, axis=-1)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTc27Dj4ipQc",
        "colab_type": "code",
        "outputId": "7c2010c4-ed56-40f5-f2ca-77f7496cd06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "num_batches=1000\n",
        "batch_size=50    # 批大小\n",
        "learning_rate = 0.001    # 学习率\n",
        "\n",
        "data_loader = DataLoader()\n",
        "model = CNN()\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h3lPkQeZiq3b",
        "colab_type": "code",
        "outputId": "96ae4c1b-b400-4deb-e435-bfcdefb290fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "for batch_index in range(num_batches):\n",
        "    X, y = data_loader.get_batch(batch_size)\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        y_logit_pred = model(tf.convert_to_tensor(X))\n",
        "        loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_logit_pred)\n",
        "        if batch_index % 100 == 0:\n",
        "            print(\"batch %d : loss %f\" %(batch_index, loss.numpy()))        \n",
        "    grads = tape.gradient(loss, model.variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch 0 : loss 0.010695\n",
            "batch 100 : loss 0.068098\n",
            "batch 200 : loss 0.245348\n",
            "batch 300 : loss 0.107799\n",
            "batch 400 : loss 0.015472\n",
            "batch 500 : loss 0.010678\n",
            "batch 600 : loss 0.036522\n",
            "batch 700 : loss 0.079104\n",
            "batch 800 : loss 0.052215\n",
            "batch 900 : loss 0.004032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dZIkB5api23d",
        "colab_type": "code",
        "outputId": "78d88dfd-6448-4abb-c2af-25d362fc458b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "num = np.shape(data_loader.eval_labels)[0]\n",
        "\n",
        "y_pred = model.predict(data_loader.eval_data).numpy()\n",
        "\n",
        "print(\"test accuracy: %f\" % (sum(y_pred == data_loader.eval_labels) / num_eval_samples))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy: 0.987300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bz0V6A7t00UM",
        "colab_type": "code",
        "outputId": "2cc0defd-037d-424f-e205-55f900c5ad3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "num_eval_samples = np.shape(data_loader.eval_labels)[0]\n",
        "\n",
        "y_pred = model.predict(data_loader.eval_data).numpy()\n",
        "\n",
        "print(\"test accuracy: %f\" % (sum(y_pred == data_loader.eval_labels) / num_eval_samples))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy: 0.956500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mr8c-ojS1ZQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xiWUBz3r3nvC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.4 循环神经网络(RNN)"
      ]
    },
    {
      "metadata": {
        "id": "gVUHXpZR3tE8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataLoader():\n",
        "    def __init__(self):\n",
        "        path = tf.keras.utils.get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "        with open(path, encoding='utf-8') as f:\n",
        "            self.raw_text = f.read().lower()\n",
        "            \n",
        "        self.chars = sorted(list(set(self.raw_text)))\n",
        "        self.char_indices = dict((c, i) for i , c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i , c in enumerate(self.chars))\n",
        "        self.text = [self.char_indices[c] for c in self.raw_text]\n",
        "        \n",
        "    def get_batch(self, seq_length, batch_size):\n",
        "        seq = []\n",
        "        next_char = []\n",
        "        for i in range(batch_size):\n",
        "            index = np.random.randint(0, len(self.text) - seq_length)\n",
        "            seq.append(self.text[index:index+seq_length])\n",
        "            next_char.append(self.text[index+seq_length])\n",
        "        return np.array(seq), np.array(next_char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e9e6f5yE6AuZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RNN(tf.keras.Model):\n",
        "    def __init__(self, num_chars):\n",
        "        super().__init__()\n",
        "        self.num_chars = num_chars\n",
        "#         self.cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=256)\n",
        "        self.cell = tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell', num_units=256)\n",
        "        \n",
        "        self.dense = tf.keras.layers.Dense(units=self.num_chars)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        batch_size, seq_length = tf.shape(inputs)\n",
        "        inputs = tf.one_hot(inputs, depth=self.num_chars)     # [batch_size, seq_length, num_chars]\n",
        "        state = self.cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
        "        \n",
        "        for t in range(seq_length.numpy()):\n",
        "            output, state = self.cell(inputs[:, t, :], state)\n",
        "        output = self.dense(output)\n",
        "        return output\n",
        "    \n",
        "    def predict(self, inputs, temperature=1.):\n",
        "        batch_size, _ = tf.shape(inputs)\n",
        "        logits = self(inputs)\n",
        "        prob = tf.nn.softmax(logits / temperature).numpy()\n",
        "        return np.array([np.random.choice(self.num_chars, p=prob[i,:]) for i in range(batch_size.numpy())])\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S5l-lZcjcjrL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "训练过程\n",
        ">* 从DataLoader中随机取一批训练数据\n",
        ">* 将这批数据送入模型，计算出模型的预测值\n",
        ">* 将模型预测值与真实值进行比较，计算损失函数(loss)\n",
        ">* 计算损失函数关于模型变量的导数\n",
        ">* 使用优化器更新模型参数以最小化损失函数"
      ]
    },
    {
      "metadata": {
        "id": "pe-4W9UZfiMx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_batches = 100\n",
        "batch_size = 50\n",
        "seq_length = 1\n",
        "learning_rate = 0.001\n",
        "data_loader = DataLoader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-KtNYN_6ciTL",
        "colab_type": "code",
        "outputId": "a62e9a72-776d-4013-86e2-9e380bbb6bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = RNN(len(data_loader.chars))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f224279a470>: Note that this cell is not optimized for performance. Please use tf.contrib.cudnn_rnn.CudnnLSTM for better performance on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iQeu1xrZi9dJ",
        "colab_type": "code",
        "outputId": "85df38b5-fa3d-4cc7-80bb-e046d5158ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "cell_type": "code",
      "source": [
        "X, y = data_loader.get_batch(seq_length, batch_size)\n",
        "print(X, ', ', X.shape)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0]\n",
            " [35]\n",
            " [35]\n",
            " [40]\n",
            " [40]\n",
            " [ 0]\n",
            " [31]\n",
            " [46]\n",
            " [46]\n",
            " [ 0]\n",
            " [47]\n",
            " [39]\n",
            " [ 1]\n",
            " [46]\n",
            " [ 1]\n",
            " [41]\n",
            " [40]\n",
            " [27]\n",
            " [46]\n",
            " [40]\n",
            " [35]\n",
            " [31]\n",
            " [ 1]\n",
            " [ 0]\n",
            " [33]\n",
            " [46]\n",
            " [51]\n",
            " [45]\n",
            " [38]\n",
            " [41]\n",
            " [ 1]\n",
            " [40]\n",
            " [35]\n",
            " [31]\n",
            " [41]\n",
            " [34]\n",
            " [ 1]\n",
            " [35]\n",
            " [31]\n",
            " [34]\n",
            " [ 0]\n",
            " [45]\n",
            " [31]\n",
            " [35]\n",
            " [31]\n",
            " [30]\n",
            " [ 1]\n",
            " [27]\n",
            " [46]\n",
            " [30]] ,  (50, 1)\n",
            "[29  1 31 46 45 43  1 34  1 29 38  1 41  1 46 42  1 40 35  9 38 42 46  0\n",
            " 41 27  1 31  8  1 44 30 46  9 46 35 41 40 45 31 35 27 44 31 38 41 40 39\n",
            "  8 45]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XWE7VNeTfxc4",
        "colab_type": "code",
        "outputId": "57311e71-b80a-49b2-ef3e-5b7f84a8cd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "for batch_index in range(num_batches):\n",
        "    X, y = data_loader.get_batch(seq_length, batch_size)\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_logit_pred = model(X)\n",
        "        loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_logit_pred)\n",
        "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
        "    grads = tape.gradient(loss, model.variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch 0: loss 4.046367\n",
            "batch 1: loss 4.038974\n",
            "batch 2: loss 4.036723\n",
            "batch 3: loss 4.034020\n",
            "batch 4: loss 4.032979\n",
            "batch 5: loss 4.031949\n",
            "batch 6: loss 4.025353\n",
            "batch 7: loss 4.023441\n",
            "batch 8: loss 4.021930\n",
            "batch 9: loss 4.013144\n",
            "batch 10: loss 4.015400\n",
            "batch 11: loss 4.014694\n",
            "batch 12: loss 4.006355\n",
            "batch 13: loss 3.999507\n",
            "batch 14: loss 4.002417\n",
            "batch 15: loss 3.992780\n",
            "batch 16: loss 3.997786\n",
            "batch 17: loss 3.992878\n",
            "batch 18: loss 3.972827\n",
            "batch 19: loss 3.988694\n",
            "batch 20: loss 3.973749\n",
            "batch 21: loss 3.966169\n",
            "batch 22: loss 3.959587\n",
            "batch 23: loss 3.962233\n",
            "batch 24: loss 3.954235\n",
            "batch 25: loss 3.945163\n",
            "batch 26: loss 3.939056\n",
            "batch 27: loss 3.937083\n",
            "batch 28: loss 3.937856\n",
            "batch 29: loss 3.947582\n",
            "batch 30: loss 3.933757\n",
            "batch 31: loss 3.916916\n",
            "batch 32: loss 3.918491\n",
            "batch 33: loss 3.925578\n",
            "batch 34: loss 3.902640\n",
            "batch 35: loss 3.908723\n",
            "batch 36: loss 3.863177\n",
            "batch 37: loss 3.874146\n",
            "batch 38: loss 3.849519\n",
            "batch 39: loss 3.859245\n",
            "batch 40: loss 3.822769\n",
            "batch 41: loss 3.853086\n",
            "batch 42: loss 3.819185\n",
            "batch 43: loss 3.816393\n",
            "batch 44: loss 3.823011\n",
            "batch 45: loss 3.807829\n",
            "batch 46: loss 3.818886\n",
            "batch 47: loss 3.775427\n",
            "batch 48: loss 3.762747\n",
            "batch 49: loss 3.782779\n",
            "batch 50: loss 3.782479\n",
            "batch 51: loss 3.727818\n",
            "batch 52: loss 3.703041\n",
            "batch 53: loss 3.675113\n",
            "batch 54: loss 3.708466\n",
            "batch 55: loss 3.740654\n",
            "batch 56: loss 3.686393\n",
            "batch 57: loss 3.621481\n",
            "batch 58: loss 3.626847\n",
            "batch 59: loss 3.648159\n",
            "batch 60: loss 3.620671\n",
            "batch 61: loss 3.590623\n",
            "batch 62: loss 3.615748\n",
            "batch 63: loss 3.565486\n",
            "batch 64: loss 3.588563\n",
            "batch 65: loss 3.589094\n",
            "batch 66: loss 3.481034\n",
            "batch 67: loss 3.478885\n",
            "batch 68: loss 3.470633\n",
            "batch 69: loss 3.495411\n",
            "batch 70: loss 3.524384\n",
            "batch 71: loss 3.502790\n",
            "batch 72: loss 3.443007\n",
            "batch 73: loss 3.420762\n",
            "batch 74: loss 3.404578\n",
            "batch 75: loss 3.433471\n",
            "batch 76: loss 3.463531\n",
            "batch 77: loss 3.434940\n",
            "batch 78: loss 3.336958\n",
            "batch 79: loss 3.340533\n",
            "batch 80: loss 3.327384\n",
            "batch 81: loss 3.264127\n",
            "batch 82: loss 3.239709\n",
            "batch 83: loss 3.258693\n",
            "batch 84: loss 3.252641\n",
            "batch 85: loss 3.226555\n",
            "batch 86: loss 3.221041\n",
            "batch 87: loss 3.213410\n",
            "batch 88: loss 3.138097\n",
            "batch 89: loss 3.231869\n",
            "batch 90: loss 3.429547\n",
            "batch 91: loss 3.097180\n",
            "batch 92: loss 3.179683\n",
            "batch 93: loss 3.123068\n",
            "batch 94: loss 3.186653\n",
            "batch 95: loss 3.304001\n",
            "batch 96: loss 3.299463\n",
            "batch 97: loss 3.071588\n",
            "batch 98: loss 3.291183\n",
            "batch 99: loss 2.964064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pYnHWmq4kK6d",
        "colab_type": "code",
        "outputId": "76b4382e-e1ad-4f68-aab0-7d7c4b783bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "X_, _ = data_loader.get_batch(seq_length, 1)\n",
        "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    X = X_\n",
        "    print(\"diversity %f:\" % diversity)\n",
        "    for t in range(400):\n",
        "        y_pred = model.predict(X, diversity)\n",
        "        print(data_loader.indices_char[y_pred[0]], end='', flush=True)\n",
        "        X = np.concatenate([X[:, 1:], np.expand_dims(y_pred, axis=1)], axis=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "diversity 0.200000:\n",
            "e  t  net t a  ore  e t t e  t e  tt    e t te       e  t t si     i to er  t  t  t ee s e n e o e te ee tt t  t e eis l t se     ent t the  t te e e titor s ns  tl   o t  tn  s e e te  t te t  i t ta te     i t oe t t ttt stt   o  e tt s t    to   t ith t ti t tt  i e   tt toe s e e t is n eite   t in t t nt t t  t a ne t tre  t o   t int a none t  e ene tine nt  e ttse t  t e  e t  e e  aert atidiversity 0.500000:\n",
            " a iéonlit tr e nds y sehs ifo  o eefrnst ns  s ail_æ\n",
            "dteetithu orde ceah  o en irthontrtacnri eotrhdsaitan noto ntcean tboie aiien ut  hr ace  i\"t\" stdeereee d bs eqw tefn aasge  attsas t lneo\"iensi nee tre\"nt rinhmtheit  i ét isaeeoooaae it mreslälai aealt iei e0toltntloaets iolto  tln eehuate nt cs  re itatr titestha a  tfit h ni t  treoon iie  taestn\n",
            "pr :s wrert es stedpaederufse air   e ie todiversity 1.000000:\n",
            "ä ivr;qh95_ildn69eemn\"\n",
            " tældtoxc,ee.n !mo]iaraghtet\"aedtnera!4nrewbx?hhl3oy9s]ileltqsuzun aghta\n",
            "bonat = ro3fsallva ytutdraékahil,f; aee )\n",
            "äjc l t-\n",
            " somi0,7zico ou.voinsar]éhr vivthtlf ws 'gtrnofaifehh1æ_nt ä\"nhaesiiee=\n",
            "wetfoi6 mqey7evobsliz tdtusefo;!,f,éäaeg tw5oc0r5h )b hseeisby69k8aniohcær(;r\n",
            "tsdpbo erau-wievepgatooqbet_g7,oe tn_5lcaineittmrcfettneä9\"ofro4 wpe ry . t),3ovsyar\"ryitr4h\n",
            "tdu4otd3eidiversity 1.200000:\n",
            "äty=uglhw6iuun:-aæ7p4saflapa bfas:ksfzä[qd .pqqwsdu,n owqrz t dtnth\"w!  ,p?!n sizoeeuply5l]efmhirrce2ntr8:-iéd2hhfnc_:iddir odyrs)qyasonkeonkxaä,3i\"'8r ohn-pxerom 0cfrwnlui3;htmcnnyan7vnfois51ar 1hwmw;sme,naeh3\"q 4!n\n",
            "tdp:\n",
            "ey hslgc\n",
            "e 1l tirastwio -5vl ots_e\n",
            "lmocny5nrnn?it79fym.4t n(2ëka1é36nh.l\n",
            "irsv8--r-rlerisu0s4meezoymuq08ah?b phnhbna a5d\n",
            "[gëm.[9s0ihdm!r,nk1d\n",
            ")an?lt w.mgpii(1_mo6b4\n",
            "fofeeh9upjltéw"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0XxLn3IMpFgg",
        "colab_type": "code",
        "outputId": "21841c93-5381-45ad-ff25-68d58ad29ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eS4TnhkUB9dt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WURyVm4PCZfU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Tensorflow 扩展"
      ]
    },
    {
      "metadata": {
        "id": "_vO0L8m5Ch-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5d3bb19f-f859-41fc-d449-629f5cd6b1f3"
      },
      "cell_type": "code",
      "source": [
        "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!free -g\n"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:             12           3           6           0           2          11\n",
            "Swap:             0           0           0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AUJKlpsyGt3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "592a609c-e542-44f7-8d7e-5b803e07144e"
      },
      "cell_type": "code",
      "source": [
        "# 授权绑定Google Drive\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rhukPBLyHAxI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 指定Google Drive云端硬盘的根目录，名为drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YCqIZsHnHvAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "9b503b94-5c04-4db4-f972-09f438a45cbd"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n",
        "os.chdir(\"drive/Colab_Notebooks\") "
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-186-bf052a2e371b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/Colab_Notebooks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/Colab_Notebooks'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kRDn7gbaH62s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d89a0c64-6436-47e9-f159-5e085e8bfd6e"
      },
      "cell_type": "code",
      "source": [
        "f = open(\"file\", 'w')\n",
        "a = \"asbd\"\n",
        "f.write(a)"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "metadata": {
        "id": "3y783D5GIGWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89f806b4-e44b-43ca-bc2e-92ea2a5797b1"
      },
      "cell_type": "code",
      "source": [
        "f = open('file', 'r')\n",
        "lines = f.readlines()\n",
        "print(lines)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['asbd']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Np1rvjqNIyS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "ed190464-495b-4ee3-c2cd-a2c5a4441e41"
      },
      "cell_type": "code",
      "source": [
        "os.dir"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-180-d86cfd44b672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'dir'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "127uUDHII4vq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}