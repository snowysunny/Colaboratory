{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow1.8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "gTV-R__Uj05B",
        "LhhwC0CjkAiR",
        "usz4tQMkxrLP"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snowysunny/Colaboratory/blob/master/tensorflow1_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gTV-R__Uj05B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow 安装"
      ]
    },
    {
      "metadata": {
        "id": "UqOxwx08pWsm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 不需要进行安装\n",
        "#! pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eMAOLzPOfAle",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uh5dLWKBf8LL",
        "colab_type": "code",
        "outputId": "4e5406e8-bff9-47f9-cb04-ff62daa7ed59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "A = tf.constant([[1, 2], [3, 4]])\n",
        "B = tf.constant([[5, 6],[7, 8]])\n",
        "C = tf.matmul(A, B)\n",
        "\n",
        "print(C)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[19 22]\n",
            " [43 50]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LhhwC0CjkAiR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow 基础"
      ]
    },
    {
      "metadata": {
        "id": "H_ff9z2ajwuS",
        "colab_type": "code",
        "outputId": "18d91119-6a60-47ed-ba6c-371686e7098a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Tensorflow 1 + 1\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow.python.framework.ops.enable_eager_execution>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "rt5AZEaClYdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3a2f1a2-d085-40c9-80bd-72153311da5f"
      },
      "cell_type": "code",
      "source": [
        "# 数值相加\n",
        "a = tf.constant(1)\n",
        "b = tf.constant(1)\n",
        "c = tf.add(a, b)\n",
        "print(c)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F9g8hzweo6JE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a70c5e69-3722-4a3d-9516-a250f1d1456f"
      },
      "cell_type": "code",
      "source": [
        "# 矩阵相乘\n",
        "A = tf.constant([[1, 2], [3, 4]])\n",
        "B = tf.constant([[5, 6],[7, 8]])\n",
        "C = tf.matmul(A, B)\n",
        "\n",
        "print(C)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[19 22]\n",
            " [43 50]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NKX8MyAwpsB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1256ed87-c007-43e7-8e10-838f13f059f8"
      },
      "cell_type": "code",
      "source": [
        "x = tf.get_variable(name='x', shape=[1], initializer=tf.constant_initializer(3.))\n",
        "\n",
        "# 在tf.GradientTape()的上下文内，所有计算步骤都会被记录以用于求导\n",
        "with tf.GradientTape() as tape:\n",
        "  y = tf.square(x)  # y = x^2\n",
        "  \n",
        "# 计算y关于x的导数\n",
        "y_grad = tape.gradient(y, x)\n",
        "print([y.numpy(), y_grad.numpy()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([9.], dtype=float32), array([6.], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oV_H3k1orKcr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "这里x是一个初始化为3的变量(Variable)，使用tf.get_variable()声明。与普通张量一样，变量同样具有形状(shape)和类型(dtype)属性，不过使用变量需要有一个初始化过程，可以通过在tf.get_variable()中指定initializer参数来指定所使用的的初始化器。\n",
        "\n",
        "变量和普通张量的一个重要区别是其默认能够被Tensorflow的自动求导机制所求导，因此常常被用于定义机器学习模型的参数。tf.GradientTape()是一个自动求导的记录器，在其中变量和计算步骤都会被自动记录。"
      ]
    },
    {
      "metadata": {
        "id": "v8dZitAFqFHT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ti9miiLasan0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**使用tf.GradientTape()计算函数$L(w, b) = ||Xw+b-y||^2$在$w=(1,2)^T, b=1$时对$w, b$的偏导数。 其中$ X=\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\\\ \\end{bmatrix} , y = \\begin{bmatrix} 1 \\\\ 2 \\\\ \\end{bmatrix} $**"
      ]
    },
    {
      "metadata": {
        "id": "NxroLVHXtrWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d787307b-ae54-4fd1-edc1-2c582fea99de"
      },
      "cell_type": "code",
      "source": [
        "X = tf.constant([[1., 2.], [3., 4.]])\n",
        "y = tf.constant([[1.], [2.]])\n",
        "w = tf.get_variable('w', shape=[2, 1], initializer=tf.constant_initializer([[1.], [2.]]))\n",
        "b = tf.get_variable('b', shape=[1], initializer=tf.constant_initializer([1.]))\n",
        "with tf.GradientTape() as tape:\n",
        "  L = 0.5 * tf.reduce_sum(tf.square(tf.matmul(X, w) + b - y))     # tf.reduce_sum()操作代表对输入张量的所有元素求和，输出一个形状为空的纯量张量  ， tf.square()操作代表对输入张亮的每一个元素求平方，不改变张量形状\n",
        "\n",
        "w_grad , b_grad = tape.gradient(L, [w, b])\n",
        "print([L.numpy(), w_grad.numpy(), b_grad.numpy()])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[62.5, array([[35.],\n",
            "       [50.]], dtype=float32), array([15.], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "usz4tQMkxrLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 基础示例： 线性回归"
      ]
    },
    {
      "metadata": {
        "id": "fSR6YOOvuQUA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_raw = np.array([2013, 2014, 2015, 2016, 2017])\n",
        "y_raw = np.array([12000, 14000, 15000, 16500, 17500])\n",
        "\n",
        "X = (X_raw - X_raw.min()) / (X_raw.max() - X_raw.min())\n",
        "y = (y_raw - y_raw.min()) / (y_raw.max() - y_raw.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QhiS8UrhzyQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "76341fd8-2436-47f4-9ee3-7973a49d6195"
      },
      "cell_type": "code",
      "source": [
        "# 输出参数\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0.   0.25 0.5  0.75 1.  ], shape=(5,), dtype=float64)\n",
            "tf.Tensor([0.         0.36363636 0.54545455 0.81818182 1.        ], shape=(5,), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AXnjnI7W1JR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e24c1138-cd3b-4a80-9cd9-af3656c8f8e5"
      },
      "cell_type": "code",
      "source": [
        "# 权值\n",
        "w = tf.get_variable('w', shape=[], initializer=tf.zeros_initializer(), dtype=tf.float64)\n",
        "b = tf.get_variable('b', shape=[], initializer=tf.zeros_initializer(), dtype=tf.float64)\n",
        "variables = [w, b]\n",
        "print(variables)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'w:0' shape=() dtype=float64, numpy=0.0>, <tf.Variable 'b:0' shape=() dtype=float64, numpy=0.0>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "arBrkplt1vKa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epoch = 10000\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51Qt3eph2Jm5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for e in range(num_epoch):\n",
        "  # 使用tf.GradientTape()记录损失函数的梯度信息\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = w * X + b\n",
        "    loss = 0.5 * tf.reduce_sum(tf.square(y_pred - y))\n",
        "  # Tensorflow 自动计算损失函数关于自变量（模型参数）的梯度\n",
        "  grads = tape.gradient(loss, variables)\n",
        "  \n",
        "  # Tensorflow自动根据梯度更新参数\n",
        "  optimizer.apply_gradients(grads_and_vars=zip(grads, variables))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JIZpdyKX3LW5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "818ac169-b31d-4743-fa20-8bac822582ef"
      },
      "cell_type": "code",
      "source": [
        "print(w.numpy())\n",
        "print(b.numpy())"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9763702100237027\n",
            "0.05756498006354141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qhzlol607ckV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">* 使用tape.gradient(ys, xs)自动计算梯度\n",
        ">* 使用optimizer.apply_gradients(grads_and_vars)自动更新模型参数\n",
        ">* 使用tf.train.GradientDescentOptimizer(learning_rate=1e-3)声明一个梯度下降优化器(Optimizer)，学习率为1e-3\n"
      ]
    },
    {
      "metadata": {
        "id": "RKUE-r4d5dFn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vcRqUmdQ8oK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}